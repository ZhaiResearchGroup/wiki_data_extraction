{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pickle\n",
    "import itertools\n",
    "from multiprocessing import Pool\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import metapy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PROCESSES=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wiki_old_updated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up error logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "# modified from https://stackoverflow.com/questions/11232230/logging-to-two-files-with-different-settings\n",
    "def generate_logger(name):\n",
    "    handler = logging.FileHandler('{}.log'.format(name), mode='w')\n",
    "    handler.setFormatter(formatter)\n",
    "\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "loggers = [generate_logger('search/wiki_{}/wiki_{}'.format(i, i)) for i in range(1, 9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = df['document'].tolist()\n",
    "# len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorizer = TfidfVectorizer()\n",
    "# vectorizer.fit_transform(corpus)\n",
    "pickle_in = open(\"out/vectorizer.pickle\",\"rb\")\n",
    "vectorizer = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform our raw queries using tf idf\n",
    "def transform_query(raw_query):\n",
    "    sparse_query = vectorizer.transform([raw_query])\n",
    "    return sparse_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the queries using MeTaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_doc(sentences, filename, p_index):\n",
    "    # write document to file\n",
    "    with open(filename, 'w+') as doc_file:\n",
    "        for sentence in sentences:\n",
    "            doc_file.write(\"{}\\n\".format(sentence))\n",
    "    \n",
    "    # write metadata\n",
    "    with open('search/wiki_{}/metadata.dat'.format(p_index), 'w+') as meta_file:\n",
    "        for i in range(len(sentences)):\n",
    "            meta_file.write(\"SEN{}\\n\".format(i))\n",
    "\n",
    "def remove_old_idx(p_index):\n",
    "    call([\"rm\", \"-rf\", \"search/idx_{}\".format(p_index)])\n",
    "    \n",
    "def init_doc_search(sentences, p_index):\n",
    "    write_doc(sentences, 'search/wiki_{}/wiki_{}.dat'.format(p_index, p_index), p_index)\n",
    "    remove_old_idx(p_index)\n",
    "    \n",
    "def get_stringified_list(idx, search_results):\n",
    "    return [idx.metadata(doc_id).get('content') for (doc_id, score) in search_results]\n",
    "\n",
    "# normalized = score / (num words in query) * log(num documents)\n",
    "def normalize_scores(search_results, sentences, summary):\n",
    "    num_words_in_query = len(summary.split(\" \"))\n",
    "    num_sentences = len(sentences)\n",
    "    \n",
    "    f = lambda score: score / (num_words_in_query * np.log10(num_sentences)) if (num_words_in_query * np.log10(num_sentences)) > 0 else np.nan\n",
    "    return [f(score) for (doc_id, score) in search_results]\n",
    "\n",
    "def search(sentences, summary, p_index, num_results=5):\n",
    "    idx = metapy.index.make_inverted_index('search/config_{}.toml'.format(p_index))\n",
    "    \n",
    "    ranker = metapy.index.OkapiBM25()\n",
    "    \n",
    "    query = metapy.index.Document()\n",
    "    query.content(summary)\n",
    "    \n",
    "    search_results = ranker.score(idx, query, num_results=num_results)\n",
    "\n",
    "    normalized_scores = normalize_scores(search_results, sentences, summary)\n",
    "    \n",
    "    stringified_results = get_stringified_list(idx, search_results)\n",
    "\n",
    "    return list(zip(stringified_results, normalized_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sen_tokens(document):\n",
    "    sentences = sent_tokenize(document)\n",
    "    sens_with_tokens = [\" \".join([\"<SOS>\", s, \"<EOS>\"]) for s in sentences]\n",
    "    new_document = \" \".join(sens_with_tokens)\n",
    "    return new_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate raw and transform queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries(args):\n",
    "    p_df, p_index = args\n",
    "    \n",
    "    logger = loggers[p_index - 1]\n",
    "\n",
    "    data = {\"title\": [], \"raw_query\": [], \"sentence_summary\": [], \"token_document\": [], \"normalized_score\": []}\n",
    "    \n",
    "    queries = []\n",
    "\n",
    "    documents_generated = 0\n",
    "    queries_generated = 0\n",
    "\n",
    "    total_documents = p_df.shape[0]\n",
    "\n",
    "    for row in p_df.iterrows():\n",
    "        title = row[1]['title']\n",
    "        summary = row[1]['summary']\n",
    "        document = row[1]['document']\n",
    "        headers = row[1]['headers']\n",
    "        sidebar = row[1]['sidebar']\n",
    "        \n",
    "        logger.debug(title)\n",
    "        \n",
    "        if (not document.strip()) or (not summary.strip()):\n",
    "            continue\n",
    "        \n",
    "        summary_sentences = sent_tokenize(summary)\n",
    "        document_sentences = sent_tokenize(document)\n",
    "        \n",
    "        token_document = add_sen_tokens(document)\n",
    "        \n",
    "        init_doc_search(document_sentences, p_index)\n",
    "\n",
    "        for sentence in summary_sentences[:3]:\n",
    "\n",
    "            # extract query\n",
    "            raw_queries = search(document_sentences, sentence, p_index)\n",
    "            \n",
    "            for raw_query, normalized_score in raw_queries:\n",
    "                query = transform_query(raw_query)\n",
    "\n",
    "                # add query info to data\n",
    "                data[\"raw_query\"].append(raw_query)\n",
    "                data[\"sentence_summary\"].append(sentence)\n",
    "                data[\"title\"].append(title)\n",
    "                data[\"token_document\"].append(token_document)\n",
    "                data[\"normalized_score\"].append(normalized_score * (-1)) # TODO: remove -1. This is just to differentiate\n",
    "\n",
    "                queries.append(query)\n",
    "            \n",
    "                queries_generated += 1\n",
    "        \n",
    "        init_doc_search(summary_sentences, p_index)\n",
    "            \n",
    "        # more experimental queries\n",
    "        if not pd.isnull(headers):\n",
    "            for header in headers.split(\" --- \"):\n",
    "                sentence_summary = search(summary_sentences, header, p_index, num_results=1)\n",
    "                if len(sentence_summary) == 0:\n",
    "                    continue\n",
    "                \n",
    "                header_query = transform_query(header)\n",
    "\n",
    "                data[\"raw_query\"].append(header)\n",
    "                data[\"sentence_summary\"].append(sentence_summary[0][0])\n",
    "                data[\"title\"].append(title)\n",
    "                data[\"token_document\"].append(token_document)\n",
    "                data[\"normalized_score\"].append(sentence_summary[0][1])\n",
    "\n",
    "                queries.append(header_query)\n",
    "\n",
    "                queries_generated += 1\n",
    "\n",
    "        if not pd.isnull(sidebar):\n",
    "            for sidebar_entry in sidebar.split(\" --- \"):\n",
    "                sentence_summary = search(summary_sentences, sidebar_entry, p_index, num_results=1)\n",
    "                if len(sentence_summary) == 0:\n",
    "                    continue\n",
    "                \n",
    "                sidebar_query = transform_query(sidebar_entry)\n",
    "\n",
    "                data[\"raw_query\"].append(sidebar_entry)\n",
    "                data[\"sentence_summary\"].append(sentence_summary[0][0])\n",
    "                data[\"title\"].append(title)\n",
    "                data[\"token_document\"].append(token_document)\n",
    "                data[\"normalized_score\"].append(sentence_summary[0][1])\n",
    "\n",
    "                queries.append(sidebar_query)\n",
    "\n",
    "                queries_generated += 1\n",
    "        \n",
    "        documents_generated += 1\n",
    "        \n",
    "        if documents_generated % 20 == 0:\n",
    "            print(\"Process {}: Generated {} queries for {} documents, {:.4f}% complete\".format(p_index, queries_generated, documents_generated, documents_generated/total_documents * 100))\n",
    "    \n",
    "    print(\"Process {}: Finished generating queries\".format(p_index))\n",
    "\n",
    "    return pd.DataFrame(data=data), sp.sparse.vstack(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_queries_data(df_queries, queries):\n",
    "    # reorganize dataframe\n",
    "    df_final = df_queries[['title', 'raw_query', 'normalized_score', 'sentence_summary', 'token_document']]\n",
    "    df_final = df_final.reindex(df_final.index.rename('query_index'))\n",
    "    df_final.index = df_final.index.astype(int)\n",
    "    \n",
    "    # store queries matrix\n",
    "    sp.sparse.save_npz(\"out/queries_matrix.npz\", queries)\n",
    "\n",
    "    # store queries csv\n",
    "    df_final.to_csv(\"out/wiki_queries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started generating queries\n",
      "Process 4: Finished generating queries\n",
      "Process 8: Finished generating queries\n",
      "Process 2: Finished generating queries\n",
      "Process 6: Finished generating queries\n",
      "Process 1: Finished generating queries\n",
      "Process 3: Finished generating queries\n",
      "Process 7: Finished generating queries\n",
      "Process 5: Finished generating queries\n",
      "Finished generating queries\n"
     ]
    }
   ],
   "source": [
    "def generate_queries_multiprocess(df, num_processes=NUM_PROCESSES):  \n",
    "    pool = Pool(processes=num_processes)\n",
    "    \n",
    "    p_dfs = np.array_split(df, num_processes)\n",
    "    \n",
    "    args_by_process = [(p_dfs[i], i+1) for i in range(len(p_dfs))]\n",
    "    results = pool.map(generate_queries, args_by_process)\n",
    "\n",
    "    pool.close()\n",
    "\n",
    "    df_queries = pd.concat([result[0] for result in results], ignore_index=True)\n",
    "    queries = sp.sparse.vstack([result[1] for result in results])\n",
    "    \n",
    "    return df_queries, queries\n",
    "\n",
    "def create_queries():\n",
    "    print(\"Started generating queries\")\n",
    "\n",
    "    df_queries, queries = generate_queries_multiprocess(df)\n",
    "\n",
    "    store_queries_data(df_queries, queries)\n",
    "\n",
    "    print(\"Finished generating queries\")\n",
    "\n",
    "create_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # store vectorizer\n",
    "# pickle_out = open(\"out/vectorizer.pickle\",\"wb\")\n",
    "# pickle.dump(vectorizer, pickle_out)\n",
    "# pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [a for a in df[\"title\"][0:16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_df = pd.read_csv('out/wiki_queries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_index</th>\n",
       "      <th>title</th>\n",
       "      <th>raw_query</th>\n",
       "      <th>normalized_score</th>\n",
       "      <th>sentence_summary</th>\n",
       "      <th>token_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>[17] Between 1953 and 1966, two years after hi...</td>\n",
       "      <td>-0.268275</td>\n",
       "      <td>The James Bond series focuses on a fictional B...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>Ian Fleming created the fictional character of...</td>\n",
       "      <td>-0.212251</td>\n",
       "      <td>The James Bond series focuses on a fictional B...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>The Young Bond series of novels was started by...</td>\n",
       "      <td>-0.207803</td>\n",
       "      <td>The James Bond series focuses on a fictional B...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>[35] Although novelizations of two of the Eon ...</td>\n",
       "      <td>-0.191852</td>\n",
       "      <td>The James Bond series focuses on a fictional B...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>[165] In thanks, Fleming gave the MI6 Armourer...</td>\n",
       "      <td>-0.189127</td>\n",
       "      <td>The James Bond series focuses on a fictional B...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>After Fleming's death a continuation novel, Co...</td>\n",
       "      <td>-0.316583</td>\n",
       "      <td>Since Fleming's death in 1964, eight other aut...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>[68] On 26 September 2013 Solo, written by Wil...</td>\n",
       "      <td>-0.292717</td>\n",
       "      <td>Since Fleming's death in 1964, eight other aut...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>[54] By the time he moved on to other, non-Bon...</td>\n",
       "      <td>-0.273413</td>\n",
       "      <td>Since Fleming's death in 1964, eight other aut...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>[35] Although novelizations of two of the Eon ...</td>\n",
       "      <td>-0.263316</td>\n",
       "      <td>Since Fleming's death in 1964, eight other aut...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>[151] In 2003, the company released James Bond...</td>\n",
       "      <td>-0.237223</td>\n",
       "      <td>Since Fleming's death in 1964, eight other aut...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>2015 Trigger Mortis.</td>\n",
       "      <td>-0.514481</td>\n",
       "      <td>The latest novel is Trigger Mortis by Anthony ...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>Trigger Mortis (2015).</td>\n",
       "      <td>-0.467068</td>\n",
       "      <td>The latest novel is Trigger Mortis by Anthony ...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>Anthony Horowitz.</td>\n",
       "      <td>-0.428313</td>\n",
       "      <td>The latest novel is Trigger Mortis by Anthony ...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>Trigger Mortis was released on 8 September 201...</td>\n",
       "      <td>-0.377814</td>\n",
       "      <td>The latest novel is Trigger Mortis by Anthony ...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>\"New James Bond novel Trigger Mortis resurrect...</td>\n",
       "      <td>-0.355188</td>\n",
       "      <td>The latest novel is Trigger Mortis by Anthony ...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>Creation and inspiration</td>\n",
       "      <td>0.176326</td>\n",
       "      <td>The character has also been adapted for televi...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>Novels and related works</td>\n",
       "      <td>0.419620</td>\n",
       "      <td>Additionally Charlie Higson wrote a series on ...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>Ian Fleming novels</td>\n",
       "      <td>1.691951</td>\n",
       "      <td>The James Bond series focuses on a fictional B...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>Post-Fleming novels</td>\n",
       "      <td>1.974592</td>\n",
       "      <td>The James Bond series focuses on a fictional B...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>Young Bond</td>\n",
       "      <td>1.166907</td>\n",
       "      <td>Additionally Charlie Higson wrote a series on ...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>The Moneypenny Diaries</td>\n",
       "      <td>1.384077</td>\n",
       "      <td>Additionally Charlie Higson wrote a series on ...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>Television</td>\n",
       "      <td>2.368018</td>\n",
       "      <td>The character has also been adapted for televi...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>Radio</td>\n",
       "      <td>2.368018</td>\n",
       "      <td>The character has also been adapted for televi...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>Films</td>\n",
       "      <td>0.840076</td>\n",
       "      <td>As of 2018, there have been twenty-four films ...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>The Eon Productions films</td>\n",
       "      <td>1.114995</td>\n",
       "      <td>As of 2018, there have been twenty-four films ...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>Non-Eon films</td>\n",
       "      <td>1.690601</td>\n",
       "      <td>As of 2018, there have been twenty-four films ...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>Video games</td>\n",
       "      <td>2.368018</td>\n",
       "      <td>The character has also been adapted for televi...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>Guns, vehicles and gadgets</td>\n",
       "      <td>1.147019</td>\n",
       "      <td>Other important elements which run through mos...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>Guns</td>\n",
       "      <td>2.043138</td>\n",
       "      <td>Other important elements which run through mos...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>James Bond.txt</td>\n",
       "      <td>Gadgets</td>\n",
       "      <td>2.043138</td>\n",
       "      <td>Other important elements which run through mos...</td>\n",
       "      <td>&lt;SOS&gt; This article is about the spy series in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>477</td>\n",
       "      <td>Nasal consonant.txt</td>\n",
       "      <td>Examples of languages containing nasal occlusi...</td>\n",
       "      <td>-0.417792</td>\n",
       "      <td>Nasal occlusives are nearly universal in human...</td>\n",
       "      <td>&lt;SOS&gt; This article is about nasal stop consona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>478</td>\n",
       "      <td>Nasal consonant.txt</td>\n",
       "      <td>A few languages have phonemic voiceless nasal ...</td>\n",
       "      <td>-0.396725</td>\n",
       "      <td>Nasal occlusives are nearly universal in human...</td>\n",
       "      <td>&lt;SOS&gt; This article is about nasal stop consona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>479</td>\n",
       "      <td>Nasal consonant.txt</td>\n",
       "      <td>Nearly all nasal consonants are nasal occlusiv...</td>\n",
       "      <td>-0.364094</td>\n",
       "      <td>Nasal occlusives are nearly universal in human...</td>\n",
       "      <td>&lt;SOS&gt; This article is about nasal stop consona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>480</td>\n",
       "      <td>Nasal consonant.txt</td>\n",
       "      <td>What would be coda nasal occlusives in other W...</td>\n",
       "      <td>-0.333425</td>\n",
       "      <td>Nasal occlusives are nearly universal in human...</td>\n",
       "      <td>&lt;SOS&gt; This article is about nasal stop consona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>481</td>\n",
       "      <td>Nasal consonant.txt</td>\n",
       "      <td>Since nasal vowels are phonemic, it simplifies...</td>\n",
       "      <td>-0.329562</td>\n",
       "      <td>Nasal occlusives are nearly universal in human...</td>\n",
       "      <td>&lt;SOS&gt; This article is about nasal stop consona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>482</td>\n",
       "      <td>Nasal consonant.txt</td>\n",
       "      <td>Voiceless nasals</td>\n",
       "      <td>0.995147</td>\n",
       "      <td>Examples of nasals in English are [n] and [m],...</td>\n",
       "      <td>&lt;SOS&gt; This article is about nasal stop consona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>483</td>\n",
       "      <td>Nasal consonant.txt</td>\n",
       "      <td>Other kinds of nasal consonant</td>\n",
       "      <td>1.406545</td>\n",
       "      <td>There are also other kinds of nasal consonants...</td>\n",
       "      <td>&lt;SOS&gt; This article is about nasal stop consona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>484</td>\n",
       "      <td>Nasal consonant.txt</td>\n",
       "      <td>Languages without nasals</td>\n",
       "      <td>0.663431</td>\n",
       "      <td>Examples of nasals in English are [n] and [m],...</td>\n",
       "      <td>&lt;SOS&gt; This article is about nasal stop consona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>485</td>\n",
       "      <td>Nasal consonant.txt</td>\n",
       "      <td>Lack of phonemic nasals</td>\n",
       "      <td>0.784049</td>\n",
       "      <td>Examples of nasals in English are [n] and [m],...</td>\n",
       "      <td>&lt;SOS&gt; This article is about nasal stop consona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>486</td>\n",
       "      <td>Nasal consonant.txt</td>\n",
       "      <td>Lack of phonetic nasals</td>\n",
       "      <td>0.784049</td>\n",
       "      <td>Examples of nasals in English are [n] and [m],...</td>\n",
       "      <td>&lt;SOS&gt; This article is about nasal stop consona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>487</td>\n",
       "      <td>WebCite.txt</td>\n",
       "      <td>No cached copy will appear in a WebCite search...</td>\n",
       "      <td>-0.251232</td>\n",
       "      <td>WebCite is an on-demand archiving service, des...</td>\n",
       "      <td>&lt;SOS&gt; Not to be confused with Website.. For a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>488</td>\n",
       "      <td>WebCite.txt</td>\n",
       "      <td>They then cite – instead of or in addition to ...</td>\n",
       "      <td>-0.243042</td>\n",
       "      <td>WebCite is an on-demand archiving service, des...</td>\n",
       "      <td>&lt;SOS&gt; Not to be confused with Website.. For a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>489</td>\n",
       "      <td>WebCite.txt</td>\n",
       "      <td>The service differs from the short time Google...</td>\n",
       "      <td>-0.240927</td>\n",
       "      <td>WebCite is an on-demand archiving service, des...</td>\n",
       "      <td>&lt;SOS&gt; Not to be confused with Website.. For a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>490</td>\n",
       "      <td>WebCite.txt</td>\n",
       "      <td>(However, note that the Internet Archive does ...</td>\n",
       "      <td>-0.240777</td>\n",
       "      <td>WebCite is an on-demand archiving service, des...</td>\n",
       "      <td>&lt;SOS&gt; Not to be confused with Website.. For a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>491</td>\n",
       "      <td>WebCite.txt</td>\n",
       "      <td>Conceived in 1997 by Gunther Eysenbach, WebCit...</td>\n",
       "      <td>-0.235198</td>\n",
       "      <td>WebCite is an on-demand archiving service, des...</td>\n",
       "      <td>&lt;SOS&gt; Not to be confused with Website.. For a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>492</td>\n",
       "      <td>WebCite.txt</td>\n",
       "      <td>WebCite can be used to preserve cited Internet...</td>\n",
       "      <td>-0.288636</td>\n",
       "      <td>The preservation service enables verifiability...</td>\n",
       "      <td>&lt;SOS&gt; Not to be confused with Website.. For a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>493</td>\n",
       "      <td>WebCite.txt</td>\n",
       "      <td>They then cite – instead of or in addition to ...</td>\n",
       "      <td>-0.270892</td>\n",
       "      <td>The preservation service enables verifiability...</td>\n",
       "      <td>&lt;SOS&gt; Not to be confused with Website.. For a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>494</td>\n",
       "      <td>WebCite.txt</td>\n",
       "      <td>According to their policy, after receiving leg...</td>\n",
       "      <td>-0.260523</td>\n",
       "      <td>The preservation service enables verifiability...</td>\n",
       "      <td>&lt;SOS&gt; Not to be confused with Website.. For a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>WebCite.txt</td>\n",
       "      <td>Conceived in 1997 by Gunther Eysenbach, WebCit...</td>\n",
       "      <td>-0.245968</td>\n",
       "      <td>The preservation service enables verifiability...</td>\n",
       "      <td>&lt;SOS&gt; Not to be confused with Website.. For a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>WebCite.txt</td>\n",
       "      <td>\"Going, Going, Still There: Using the WebCite ...</td>\n",
       "      <td>-0.245310</td>\n",
       "      <td>The preservation service enables verifiability...</td>\n",
       "      <td>&lt;SOS&gt; Not to be confused with Website.. For a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>WebCite.txt</td>\n",
       "      <td>3 Fundraising.</td>\n",
       "      <td>-3.142625</td>\n",
       "      <td>[3]</td>\n",
       "      <td>&lt;SOS&gt; Not to be confused with Website.. For a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>WebCite.txt</td>\n",
       "      <td>50,418 (November 2017[update])[2].</td>\n",
       "      <td>-2.137099</td>\n",
       "      <td>[3]</td>\n",
       "      <td>&lt;SOS&gt; Not to be confused with Website.. For a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>WebCite.txt</td>\n",
       "      <td>References[edit].</td>\n",
       "      <td>-2.019704</td>\n",
       "      <td>[3]</td>\n",
       "      <td>&lt;SOS&gt; Not to be confused with Website.. For a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>500</td>\n",
       "      <td>WebCite.txt</td>\n",
       "      <td>Process[edit].</td>\n",
       "      <td>-2.019704</td>\n",
       "      <td>[3]</td>\n",
       "      <td>&lt;SOS&gt; Not to be confused with Website.. For a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>501</td>\n",
       "      <td>WebCite.txt</td>\n",
       "      <td>Fundraising[edit].</td>\n",
       "      <td>-2.019704</td>\n",
       "      <td>[3]</td>\n",
       "      <td>&lt;SOS&gt; Not to be confused with Website.. For a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>502</td>\n",
       "      <td>WebCite.txt</td>\n",
       "      <td>Comparison to other services</td>\n",
       "      <td>0.469142</td>\n",
       "      <td>The preservation service enables verifiability...</td>\n",
       "      <td>&lt;SOS&gt; Not to be confused with Website.. For a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>503</td>\n",
       "      <td>WebCite.txt</td>\n",
       "      <td>WebCite</td>\n",
       "      <td>1.615188</td>\n",
       "      <td>WebCite is an on-demand archiving service, des...</td>\n",
       "      <td>&lt;SOS&gt; Not to be confused with Website.. For a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>504</td>\n",
       "      <td>WebCite.txt</td>\n",
       "      <td>University of Toronto[1]</td>\n",
       "      <td>2.169078</td>\n",
       "      <td>[3]</td>\n",
       "      <td>&lt;SOS&gt; Not to be confused with Website.. For a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>505</td>\n",
       "      <td>WebCite.txt</td>\n",
       "      <td>Created by</td>\n",
       "      <td>0.899166</td>\n",
       "      <td>The preservation service enables verifiability...</td>\n",
       "      <td>&lt;SOS&gt; Not to be confused with Website.. For a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>506</td>\n",
       "      <td>WebCite.txt</td>\n",
       "      <td>Preserving for posterity</td>\n",
       "      <td>0.625523</td>\n",
       "      <td>The preservation service enables verifiability...</td>\n",
       "      <td>&lt;SOS&gt; Not to be confused with Website.. For a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>507 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query_index                title  \\\n",
       "0              0       James Bond.txt   \n",
       "1              1       James Bond.txt   \n",
       "2              2       James Bond.txt   \n",
       "3              3       James Bond.txt   \n",
       "4              4       James Bond.txt   \n",
       "5              5       James Bond.txt   \n",
       "6              6       James Bond.txt   \n",
       "7              7       James Bond.txt   \n",
       "8              8       James Bond.txt   \n",
       "9              9       James Bond.txt   \n",
       "10            10       James Bond.txt   \n",
       "11            11       James Bond.txt   \n",
       "12            12       James Bond.txt   \n",
       "13            13       James Bond.txt   \n",
       "14            14       James Bond.txt   \n",
       "15            15       James Bond.txt   \n",
       "16            16       James Bond.txt   \n",
       "17            17       James Bond.txt   \n",
       "18            18       James Bond.txt   \n",
       "19            19       James Bond.txt   \n",
       "20            20       James Bond.txt   \n",
       "21            21       James Bond.txt   \n",
       "22            22       James Bond.txt   \n",
       "23            23       James Bond.txt   \n",
       "24            24       James Bond.txt   \n",
       "25            25       James Bond.txt   \n",
       "26            26       James Bond.txt   \n",
       "27            27       James Bond.txt   \n",
       "28            28       James Bond.txt   \n",
       "29            29       James Bond.txt   \n",
       "..           ...                  ...   \n",
       "477          477  Nasal consonant.txt   \n",
       "478          478  Nasal consonant.txt   \n",
       "479          479  Nasal consonant.txt   \n",
       "480          480  Nasal consonant.txt   \n",
       "481          481  Nasal consonant.txt   \n",
       "482          482  Nasal consonant.txt   \n",
       "483          483  Nasal consonant.txt   \n",
       "484          484  Nasal consonant.txt   \n",
       "485          485  Nasal consonant.txt   \n",
       "486          486  Nasal consonant.txt   \n",
       "487          487          WebCite.txt   \n",
       "488          488          WebCite.txt   \n",
       "489          489          WebCite.txt   \n",
       "490          490          WebCite.txt   \n",
       "491          491          WebCite.txt   \n",
       "492          492          WebCite.txt   \n",
       "493          493          WebCite.txt   \n",
       "494          494          WebCite.txt   \n",
       "495          495          WebCite.txt   \n",
       "496          496          WebCite.txt   \n",
       "497          497          WebCite.txt   \n",
       "498          498          WebCite.txt   \n",
       "499          499          WebCite.txt   \n",
       "500          500          WebCite.txt   \n",
       "501          501          WebCite.txt   \n",
       "502          502          WebCite.txt   \n",
       "503          503          WebCite.txt   \n",
       "504          504          WebCite.txt   \n",
       "505          505          WebCite.txt   \n",
       "506          506          WebCite.txt   \n",
       "\n",
       "                                             raw_query  normalized_score  \\\n",
       "0    [17] Between 1953 and 1966, two years after hi...         -0.268275   \n",
       "1    Ian Fleming created the fictional character of...         -0.212251   \n",
       "2    The Young Bond series of novels was started by...         -0.207803   \n",
       "3    [35] Although novelizations of two of the Eon ...         -0.191852   \n",
       "4    [165] In thanks, Fleming gave the MI6 Armourer...         -0.189127   \n",
       "5    After Fleming's death a continuation novel, Co...         -0.316583   \n",
       "6    [68] On 26 September 2013 Solo, written by Wil...         -0.292717   \n",
       "7    [54] By the time he moved on to other, non-Bon...         -0.273413   \n",
       "8    [35] Although novelizations of two of the Eon ...         -0.263316   \n",
       "9    [151] In 2003, the company released James Bond...         -0.237223   \n",
       "10                                2015 Trigger Mortis.         -0.514481   \n",
       "11                              Trigger Mortis (2015).         -0.467068   \n",
       "12                                   Anthony Horowitz.         -0.428313   \n",
       "13   Trigger Mortis was released on 8 September 201...         -0.377814   \n",
       "14   \"New James Bond novel Trigger Mortis resurrect...         -0.355188   \n",
       "15                            Creation and inspiration          0.176326   \n",
       "16                            Novels and related works          0.419620   \n",
       "17                                  Ian Fleming novels          1.691951   \n",
       "18                                 Post-Fleming novels          1.974592   \n",
       "19                                          Young Bond          1.166907   \n",
       "20                              The Moneypenny Diaries          1.384077   \n",
       "21                                          Television          2.368018   \n",
       "22                                               Radio          2.368018   \n",
       "23                                               Films          0.840076   \n",
       "24                           The Eon Productions films          1.114995   \n",
       "25                                       Non-Eon films          1.690601   \n",
       "26                                         Video games          2.368018   \n",
       "27                          Guns, vehicles and gadgets          1.147019   \n",
       "28                                                Guns          2.043138   \n",
       "29                                             Gadgets          2.043138   \n",
       "..                                                 ...               ...   \n",
       "477  Examples of languages containing nasal occlusi...         -0.417792   \n",
       "478  A few languages have phonemic voiceless nasal ...         -0.396725   \n",
       "479  Nearly all nasal consonants are nasal occlusiv...         -0.364094   \n",
       "480  What would be coda nasal occlusives in other W...         -0.333425   \n",
       "481  Since nasal vowels are phonemic, it simplifies...         -0.329562   \n",
       "482                                   Voiceless nasals          0.995147   \n",
       "483                     Other kinds of nasal consonant          1.406545   \n",
       "484                           Languages without nasals          0.663431   \n",
       "485                            Lack of phonemic nasals          0.784049   \n",
       "486                            Lack of phonetic nasals          0.784049   \n",
       "487  No cached copy will appear in a WebCite search...         -0.251232   \n",
       "488  They then cite – instead of or in addition to ...         -0.243042   \n",
       "489  The service differs from the short time Google...         -0.240927   \n",
       "490  (However, note that the Internet Archive does ...         -0.240777   \n",
       "491  Conceived in 1997 by Gunther Eysenbach, WebCit...         -0.235198   \n",
       "492  WebCite can be used to preserve cited Internet...         -0.288636   \n",
       "493  They then cite – instead of or in addition to ...         -0.270892   \n",
       "494  According to their policy, after receiving leg...         -0.260523   \n",
       "495  Conceived in 1997 by Gunther Eysenbach, WebCit...         -0.245968   \n",
       "496  \"Going, Going, Still There: Using the WebCite ...         -0.245310   \n",
       "497                                     3 Fundraising.         -3.142625   \n",
       "498                 50,418 (November 2017[update])[2].         -2.137099   \n",
       "499                                  References[edit].         -2.019704   \n",
       "500                                     Process[edit].         -2.019704   \n",
       "501                                 Fundraising[edit].         -2.019704   \n",
       "502                       Comparison to other services          0.469142   \n",
       "503                                            WebCite          1.615188   \n",
       "504                           University of Toronto[1]          2.169078   \n",
       "505                                         Created by          0.899166   \n",
       "506                           Preserving for posterity          0.625523   \n",
       "\n",
       "                                      sentence_summary  \\\n",
       "0    The James Bond series focuses on a fictional B...   \n",
       "1    The James Bond series focuses on a fictional B...   \n",
       "2    The James Bond series focuses on a fictional B...   \n",
       "3    The James Bond series focuses on a fictional B...   \n",
       "4    The James Bond series focuses on a fictional B...   \n",
       "5    Since Fleming's death in 1964, eight other aut...   \n",
       "6    Since Fleming's death in 1964, eight other aut...   \n",
       "7    Since Fleming's death in 1964, eight other aut...   \n",
       "8    Since Fleming's death in 1964, eight other aut...   \n",
       "9    Since Fleming's death in 1964, eight other aut...   \n",
       "10   The latest novel is Trigger Mortis by Anthony ...   \n",
       "11   The latest novel is Trigger Mortis by Anthony ...   \n",
       "12   The latest novel is Trigger Mortis by Anthony ...   \n",
       "13   The latest novel is Trigger Mortis by Anthony ...   \n",
       "14   The latest novel is Trigger Mortis by Anthony ...   \n",
       "15   The character has also been adapted for televi...   \n",
       "16   Additionally Charlie Higson wrote a series on ...   \n",
       "17   The James Bond series focuses on a fictional B...   \n",
       "18   The James Bond series focuses on a fictional B...   \n",
       "19   Additionally Charlie Higson wrote a series on ...   \n",
       "20   Additionally Charlie Higson wrote a series on ...   \n",
       "21   The character has also been adapted for televi...   \n",
       "22   The character has also been adapted for televi...   \n",
       "23   As of 2018, there have been twenty-four films ...   \n",
       "24   As of 2018, there have been twenty-four films ...   \n",
       "25   As of 2018, there have been twenty-four films ...   \n",
       "26   The character has also been adapted for televi...   \n",
       "27   Other important elements which run through mos...   \n",
       "28   Other important elements which run through mos...   \n",
       "29   Other important elements which run through mos...   \n",
       "..                                                 ...   \n",
       "477  Nasal occlusives are nearly universal in human...   \n",
       "478  Nasal occlusives are nearly universal in human...   \n",
       "479  Nasal occlusives are nearly universal in human...   \n",
       "480  Nasal occlusives are nearly universal in human...   \n",
       "481  Nasal occlusives are nearly universal in human...   \n",
       "482  Examples of nasals in English are [n] and [m],...   \n",
       "483  There are also other kinds of nasal consonants...   \n",
       "484  Examples of nasals in English are [n] and [m],...   \n",
       "485  Examples of nasals in English are [n] and [m],...   \n",
       "486  Examples of nasals in English are [n] and [m],...   \n",
       "487  WebCite is an on-demand archiving service, des...   \n",
       "488  WebCite is an on-demand archiving service, des...   \n",
       "489  WebCite is an on-demand archiving service, des...   \n",
       "490  WebCite is an on-demand archiving service, des...   \n",
       "491  WebCite is an on-demand archiving service, des...   \n",
       "492  The preservation service enables verifiability...   \n",
       "493  The preservation service enables verifiability...   \n",
       "494  The preservation service enables verifiability...   \n",
       "495  The preservation service enables verifiability...   \n",
       "496  The preservation service enables verifiability...   \n",
       "497                                                [3]   \n",
       "498                                                [3]   \n",
       "499                                                [3]   \n",
       "500                                                [3]   \n",
       "501                                                [3]   \n",
       "502  The preservation service enables verifiability...   \n",
       "503  WebCite is an on-demand archiving service, des...   \n",
       "504                                                [3]   \n",
       "505  The preservation service enables verifiability...   \n",
       "506  The preservation service enables verifiability...   \n",
       "\n",
       "                                        token_document  \n",
       "0    <SOS> This article is about the spy series in ...  \n",
       "1    <SOS> This article is about the spy series in ...  \n",
       "2    <SOS> This article is about the spy series in ...  \n",
       "3    <SOS> This article is about the spy series in ...  \n",
       "4    <SOS> This article is about the spy series in ...  \n",
       "5    <SOS> This article is about the spy series in ...  \n",
       "6    <SOS> This article is about the spy series in ...  \n",
       "7    <SOS> This article is about the spy series in ...  \n",
       "8    <SOS> This article is about the spy series in ...  \n",
       "9    <SOS> This article is about the spy series in ...  \n",
       "10   <SOS> This article is about the spy series in ...  \n",
       "11   <SOS> This article is about the spy series in ...  \n",
       "12   <SOS> This article is about the spy series in ...  \n",
       "13   <SOS> This article is about the spy series in ...  \n",
       "14   <SOS> This article is about the spy series in ...  \n",
       "15   <SOS> This article is about the spy series in ...  \n",
       "16   <SOS> This article is about the spy series in ...  \n",
       "17   <SOS> This article is about the spy series in ...  \n",
       "18   <SOS> This article is about the spy series in ...  \n",
       "19   <SOS> This article is about the spy series in ...  \n",
       "20   <SOS> This article is about the spy series in ...  \n",
       "21   <SOS> This article is about the spy series in ...  \n",
       "22   <SOS> This article is about the spy series in ...  \n",
       "23   <SOS> This article is about the spy series in ...  \n",
       "24   <SOS> This article is about the spy series in ...  \n",
       "25   <SOS> This article is about the spy series in ...  \n",
       "26   <SOS> This article is about the spy series in ...  \n",
       "27   <SOS> This article is about the spy series in ...  \n",
       "28   <SOS> This article is about the spy series in ...  \n",
       "29   <SOS> This article is about the spy series in ...  \n",
       "..                                                 ...  \n",
       "477  <SOS> This article is about nasal stop consona...  \n",
       "478  <SOS> This article is about nasal stop consona...  \n",
       "479  <SOS> This article is about nasal stop consona...  \n",
       "480  <SOS> This article is about nasal stop consona...  \n",
       "481  <SOS> This article is about nasal stop consona...  \n",
       "482  <SOS> This article is about nasal stop consona...  \n",
       "483  <SOS> This article is about nasal stop consona...  \n",
       "484  <SOS> This article is about nasal stop consona...  \n",
       "485  <SOS> This article is about nasal stop consona...  \n",
       "486  <SOS> This article is about nasal stop consona...  \n",
       "487  <SOS> Not to be confused with Website.. For a ...  \n",
       "488  <SOS> Not to be confused with Website.. For a ...  \n",
       "489  <SOS> Not to be confused with Website.. For a ...  \n",
       "490  <SOS> Not to be confused with Website.. For a ...  \n",
       "491  <SOS> Not to be confused with Website.. For a ...  \n",
       "492  <SOS> Not to be confused with Website.. For a ...  \n",
       "493  <SOS> Not to be confused with Website.. For a ...  \n",
       "494  <SOS> Not to be confused with Website.. For a ...  \n",
       "495  <SOS> Not to be confused with Website.. For a ...  \n",
       "496  <SOS> Not to be confused with Website.. For a ...  \n",
       "497  <SOS> Not to be confused with Website.. For a ...  \n",
       "498  <SOS> Not to be confused with Website.. For a ...  \n",
       "499  <SOS> Not to be confused with Website.. For a ...  \n",
       "500  <SOS> Not to be confused with Website.. For a ...  \n",
       "501  <SOS> Not to be confused with Website.. For a ...  \n",
       "502  <SOS> Not to be confused with Website.. For a ...  \n",
       "503  <SOS> Not to be confused with Website.. For a ...  \n",
       "504  <SOS> Not to be confused with Website.. For a ...  \n",
       "505  <SOS> Not to be confused with Website.. For a ...  \n",
       "506  <SOS> Not to be confused with Website.. For a ...  \n",
       "\n",
       "[507 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_info(print_df):\n",
    "#     for row in print_df.iterrows():\n",
    "#         print(\"----- QUERY -----\")\n",
    "#         print(row[1]['raw_query'], row[1]['normalized_score'])\n",
    "#         print(\"\\n\")\n",
    "#         print(\"----- SUMMARY -----\")\n",
    "#         print(row[1]['sentence_summary'])\n",
    "#         print(\"\\n--------------------\\n\")\n",
    "\n",
    "# print_info(out_df[15:46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_info(out_df.loc[out_df.raw_query.str.len() < .5 * out_df.sentence_summary.str.len(), ['raw_query', 'sentence_summary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDEAS:\n",
    "# - pull stuff from the right-hand side as queries (ex/ \"Created by\")\n",
    "# - pull content headers as queries (ex/ \"origins\")\n",
    "# - use the title as another query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
